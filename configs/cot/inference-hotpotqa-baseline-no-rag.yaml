# @package _global_
model:
    _target_: ragfit.models.hf.HFInferencePrompt
    model_name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    load_in_4bit: false
    load_in_8bit: true
    attn_implementation: flash_attention_2
    device_map: auto
    torch_dtype:
    trust_remote_code: true
    instruction: ragfit/processing/prompts/prompt_instructions/qa-short-no-rag.txt
    template: ragfit/processing/prompts/qa-short.txt
    template_map:
        query: query
    lora_path:
    generation:
        do_sample: false
        max_new_tokens: 200
        max_length:
        temperature:
        top_k:
        top_p:
        return_full_text: false

data_file: ./data/evaluation/facebook-kilt_tasks-hotpotqa-validation-raft-context-zeroshot.jsonl
generated_file: baseline-no-rag-hotpotqa-test-generated.jsonl
input_key: prompt
generation_key: output
target_key: answers
limit: 200
